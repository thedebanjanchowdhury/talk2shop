{"version":3,"file":"tavily-crawl.js","names":["params: Record<string, unknown>","suggestions: string[]","params: TavilyCrawlAPIRetrieverFields","apiWrapperParams: { tavilyApiKey?: string; apiBaseUrl?: string }","input: InferInteropZodOutput<typeof inputSchema>","_runManager?: CallbackManagerForToolRun","effectiveCategories: CrawlCategory[] | undefined","e: unknown"],"sources":["../src/tavily-crawl.ts"],"sourcesContent":["import { CallbackManagerForToolRun } from \"@langchain/core/callbacks/manager\";\nimport { StructuredTool, ToolParams } from \"@langchain/core/tools\";\nimport { z } from \"zod/v3\";\nimport { InferInteropZodOutput } from \"@langchain/core/dist/utils/types/zod.js\";\nimport {\n  TavilyCrawlAPIWrapper,\n  type TavilyCrawlResponse,\n  ExtractDepth,\n  CrawlCategory,\n} from \"./utils.js\";\n\nexport type TavilyCrawlAPIRetrieverFields = ToolParams & {\n  /**\n   * The base URL to be used for the Tavily Search API.\n   *\n   *\n   */\n  apiBaseUrl?: string;\n\n  /**\n   * The API key used for authentication with the Tavily Search API.\n   *\n   */\n  tavilyApiKey?: string;\n\n  /**\n   * Natural language instructions to guide the crawler\n   *\n   * @default undefined\n   */\n  instructions?: string;\n\n  /**\n   * The depth of the extractions. It can be \"basic\" or \"advanced\".\n   *\n   */\n  extractDepth?: ExtractDepth;\n\n  /**\n   * The format of the respose. It can be \"markdown\" or \"text\"\n   *\n   * @default \"markdown\"\n   */\n  format?: \"markdown\" | \"text\";\n\n  /**\n   * The maximum number of hops from the starting URL.\n   *\n   * @default 3\n   */\n  maxDepth?: number;\n\n  /**\n   * The maximum number of pages to crawl per level.\n   *\n   * @default 50\n   */\n  maxBreadth?: number;\n\n  /**\n   * The maximum number of pages to crawl.\n   *\n   * @default 100\n   */\n  limit?: number;\n\n  /**\n   * Only crawl URLs containing these categories.\n   *\n   * @default undefined\n   */\n  categories?: CrawlCategory[];\n\n  /**\n   * Only crawl URLs containing these paths.\n   *\n   * @default undefined\n   */\n  selectPaths?: string[];\n\n  /**\n   * Only crawl these domains.\n   *\n   * @default undefined\n   */\n  selectDomains?: string[];\n\n  /**\n   * Exclude these paths.\n   *\n   * @default undefined\n   */\n  excludePaths?: string[];\n\n  /**\n   * Exclude these domains.\n   *\n   * @default undefined\n   */\n  excludeDomains?: string[];\n\n  /**\n   * Allow crawling external domains.\n   *\n   * @default undefined\n   */\n  allowExternal?: boolean;\n\n  /**\n   * Include images in the crawl results.\n   *\n   * @default false\n   */\n  includeImages?: boolean;\n\n  /**\n   * Include the favicon URL for each crawl result.\n   *\n   * @default false\n   */\n  includeFavicon?: boolean;\n\n  /**\n   * The name of the tool.\n   *\n   * @default \"tavily_crawl\"\n   */\n  name?: string;\n\n  /**\n   * The description of the tool.\n   *\n   * @default \"Starts a smart web crawl from a given URL.\"\n   */\n  description?: string;\n  /**\n   * Whether to return the tool's output directly.\n   *\n   * Setting this to true means that after the tool is called,\n   * an agent should stop looping.\n   *\n   * @default false\n   */\n  returnDirect?: boolean;\n\n  /**\n   * An API wrapper that can be used to interact with the Tavily Crawl API. Useful for testing.\n   *\n   * If specified, the tool will use this API wrapper instead of creating a new one, and fields used\n   * in API Wrapper initialization, like {@link TavilyCrawlAPIRetrieverFields.tavilyApiKey}, will be\n   * ignored.\n   */\n  apiWrapper?: TavilyCrawlAPIWrapper;\n};\n\nfunction generateSuggestions(params: Record<string, unknown>): string[] {\n  const suggestions: string[] = [];\n\n  const { selectPaths, selectDomains, excludeDomains } = params;\n\n  if (\n    !selectPaths ||\n    (Array.isArray(selectPaths) && selectPaths.length === 0)\n  ) {\n    suggestions.push(\"Try adding specific path filters using selectPaths\");\n  }\n  if (\n    !selectDomains ||\n    (Array.isArray(selectDomains) && selectDomains.length === 0)\n  ) {\n    suggestions.push(\"Try adding domain filters using selectDomains\");\n  }\n  if (\n    !excludeDomains ||\n    (Array.isArray(excludeDomains) && excludeDomains.length === 0)\n  ) {\n    suggestions.push(\"Try excluding specific domains using excludeDomains\");\n  }\n  return suggestions;\n}\n\nconst inputSchema = z.object({\n  url: z.string().describe(\"URL to crawl\"),\n  instructions: z\n    .string()\n    .optional()\n    .describe(\n      \"Natural language instructions for the crawler. Example: 'Python SDK'\"\n    ),\n  selectPaths: z\n    .array(z.string())\n    .optional()\n    .describe(\n      \"Regex patterns to select only URLs with specific path patterns. Example: ['/api/v1.*']\"\n    ),\n  selectDomains: z\n    .array(z.string())\n    .optional()\n    .describe(\n      \"Regex patterns to select only URLs from specific domains or subdomains. Example: ['^docs\\\\.example\\\\.com$']\"\n    ),\n  excludePaths: z\n    .array(z.string())\n    .optional()\n    .describe(\n      \"Regex patterns to exclude URLs with specific path patterns. Example: ['/private/.*', '/admin/.*']\"\n    ),\n  excludeDomains: z\n    .array(z.string())\n    .optional()\n    .describe(\n      \"Regex patterns to exclude specific domains or subdomains from crawling. Example: ['^private\\\\.example\\\\.com$']\"\n    ),\n  allowExternal: z\n    .boolean()\n    .optional()\n    .describe(\"Whether to allow following links that go to external domains.\"),\n  categories: z\n    .array(\n      z.enum([\n        \"Documentation\",\n        \"Blog\",\n        \"Blogs\",\n        \"Community\",\n        \"About\",\n        \"Contact\",\n        \"Privacy\",\n        \"Terms\",\n        \"Status\",\n        \"Pricing\",\n        \"Enterprise\",\n        \"Careers\",\n        \"E-Commerce\",\n        \"Authentication\",\n        \"Developer\",\n        \"Developers\",\n        \"Solutions\",\n        \"Partners\",\n        \"Downloads\",\n        \"Media\",\n        \"Events\",\n        \"People\",\n      ])\n    )\n    .optional()\n    .describe(\n      \"Filter URLs using predefined categories like 'Documentation', 'Blogs', etc.\"\n    ),\n});\n\nexport class TavilyCrawl extends StructuredTool<typeof inputSchema> {\n  static lc_name() {\n    return \"tavily_crawl\";\n  }\n\n  override name: string = \"tavily_crawl\";\n\n  override description: string =\n    \"A powerful web crawler that initiates a structured web crawl starting from a specified \" +\n    \"base URL. The crawler uses a BFS Depth: refering to the number of link hops from the root URL. \" +\n    \"A page directly linked from the root is at BFS depth 1, regardless of its URL structure. \" +\n    \"You can control how deep and wide it goes, and guide it to focus on specific sections of the site.\";\n\n  override schema = inputSchema;\n\n  apiBaseUrl?: string;\n\n  extractDepth?: ExtractDepth;\n\n  includeImages?: boolean;\n\n  format?: \"markdown\" | \"text\";\n\n  maxDepth?: number;\n\n  maxBreadth?: number;\n\n  limit?: number;\n\n  instructions?: string;\n\n  selectPaths?: string[];\n\n  selectDomains?: string[];\n\n  excludePaths?: string[];\n\n  excludeDomains?: string[];\n\n  allowExternal?: boolean;\n\n  categories?: CrawlCategory[];\n\n  includeFavicon?: boolean;\n\n  private apiWrapper: TavilyCrawlAPIWrapper;\n\n  constructor(params: TavilyCrawlAPIRetrieverFields = {}) {\n    super(params);\n\n    if (typeof params.name === \"string\") {\n      this.name = params.name;\n    }\n\n    if (typeof params.description === \"string\") {\n      this.description = params.description;\n    }\n\n    if (params.apiWrapper) {\n      this.apiWrapper = params.apiWrapper;\n    } else {\n      const apiWrapperParams: { tavilyApiKey?: string; apiBaseUrl?: string } =\n        {};\n      if (params.tavilyApiKey) {\n        apiWrapperParams.tavilyApiKey = params.tavilyApiKey;\n      }\n      if (params.apiBaseUrl) {\n        apiWrapperParams.apiBaseUrl = params.apiBaseUrl;\n      }\n      this.apiWrapper = new TavilyCrawlAPIWrapper(apiWrapperParams);\n    }\n\n    this.extractDepth = params.extractDepth;\n    this.includeImages = params.includeImages;\n    this.format = params.format;\n    this.maxDepth = params.maxDepth;\n    this.maxBreadth = params.maxBreadth;\n    this.limit = params.limit;\n    this.instructions = params.instructions;\n    this.selectPaths = params.selectPaths;\n    this.selectDomains = params.selectDomains;\n    this.excludePaths = params.excludePaths;\n    this.excludeDomains = params.excludeDomains;\n    this.allowExternal = params.allowExternal;\n    this.categories = params.categories;\n    this.includeFavicon = params.includeFavicon;\n  }\n\n  async _call(\n    input: InferInteropZodOutput<typeof inputSchema>,\n    _runManager?: CallbackManagerForToolRun\n  ): Promise<TavilyCrawlResponse | { error: string }> {\n    try {\n      const {\n        url,\n        instructions,\n        selectPaths,\n        selectDomains,\n        excludePaths,\n        excludeDomains,\n        allowExternal,\n        categories,\n      } = input;\n\n      // Class instance values take precedence over call parameters\n      const effectiveExtractDepth = this.extractDepth;\n      const effectiveIncludeImages = this.includeImages;\n      const effectiveFormat = this.format;\n      const effectiveMaxDepth = this.maxDepth;\n      const effectiveMaxBreadth = this.maxBreadth;\n      const effectiveLimit = this.limit;\n      const effectiveInstructions = this.instructions ?? instructions;\n      const effectiveSelectPaths = this.selectPaths ?? selectPaths;\n      const effectiveSelectDomains = this.selectDomains ?? selectDomains;\n      const effectiveExcludePaths = this.excludePaths ?? excludePaths;\n      const effectiveExcludeDomains = this.excludeDomains ?? excludeDomains;\n      const effectiveAllowExternal = this.allowExternal ?? allowExternal;\n      const effectiveIncludeFavicon = this.includeFavicon;\n      // Remove duplicates from categories and convert to array\n      let effectiveCategories: CrawlCategory[] | undefined;\n      if (this.categories) {\n        effectiveCategories = Array.from(new Set(this.categories));\n      } else if (categories) {\n        effectiveCategories = Array.from(new Set(categories));\n      } else {\n        effectiveCategories = categories;\n      }\n\n      const rawResults = await this.apiWrapper.rawResults({\n        url,\n        extractDepth: effectiveExtractDepth,\n        includeImages: effectiveIncludeImages,\n        format: effectiveFormat,\n        maxDepth: effectiveMaxDepth,\n        maxBreadth: effectiveMaxBreadth,\n        limit: effectiveLimit,\n        instructions: effectiveInstructions,\n        selectPaths: effectiveSelectPaths,\n        selectDomains: effectiveSelectDomains,\n        excludePaths: effectiveExcludePaths,\n        excludeDomains: effectiveExcludeDomains,\n        allowExternal: effectiveAllowExternal,\n        categories: effectiveCategories,\n        includeFavicon: effectiveIncludeFavicon,\n      });\n\n      if (\n        !rawResults ||\n        typeof rawResults !== \"object\" ||\n        !(\"results\" in rawResults) ||\n        !Array.isArray(rawResults.results) ||\n        rawResults.results.length === 0\n      ) {\n        const suggestions = generateSuggestions(input);\n\n        const errorMessage =\n          `No crawl results found for '${url}'. ` +\n          `Suggestions: ${suggestions.join(\", \")}. ` +\n          `Try modifying your crawl parameters with one of these approaches.`;\n\n        throw new Error(errorMessage);\n      }\n\n      return rawResults;\n    } catch (e: unknown) {\n      const errorMessage =\n        e && typeof e === \"object\" && \"message\" in e ? e.message : String(e);\n\n      return { error: errorMessage as string };\n    }\n  }\n}\n"],"mappings":";;;;;AA2JA,SAAS,oBAAoBA,QAA2C;CACtE,MAAMC,cAAwB,CAAE;CAEhC,MAAM,EAAE,aAAa,eAAe,gBAAgB,GAAG;AAEvD,KACE,CAAC,eACA,MAAM,QAAQ,YAAY,IAAI,YAAY,WAAW,GAEtD,YAAY,KAAK,qDAAqD;AAExE,KACE,CAAC,iBACA,MAAM,QAAQ,cAAc,IAAI,cAAc,WAAW,GAE1D,YAAY,KAAK,gDAAgD;AAEnE,KACE,CAAC,kBACA,MAAM,QAAQ,eAAe,IAAI,eAAe,WAAW,GAE5D,YAAY,KAAK,sDAAsD;AAEzE,QAAO;AACR;AAED,MAAM,cAAc,EAAE,OAAO;CAC3B,KAAK,EAAE,QAAQ,CAAC,SAAS,eAAe;CACxC,cAAc,EACX,QAAQ,CACR,UAAU,CACV,SACC,uEACD;CACH,aAAa,EACV,MAAM,EAAE,QAAQ,CAAC,CACjB,UAAU,CACV,SACC,yFACD;CACH,eAAe,EACZ,MAAM,EAAE,QAAQ,CAAC,CACjB,UAAU,CACV,SACC,8GACD;CACH,cAAc,EACX,MAAM,EAAE,QAAQ,CAAC,CACjB,UAAU,CACV,SACC,oGACD;CACH,gBAAgB,EACb,MAAM,EAAE,QAAQ,CAAC,CACjB,UAAU,CACV,SACC,iHACD;CACH,eAAe,EACZ,SAAS,CACT,UAAU,CACV,SAAS,gEAAgE;CAC5E,YAAY,EACT,MACC,EAAE,KAAK;EACL;EACA;EACA;EACA;EACA;EACA;EACA;EACA;EACA;EACA;EACA;EACA;EACA;EACA;EACA;EACA;EACA;EACA;EACA;EACA;EACA;EACA;CACD,EAAC,CACH,CACA,UAAU,CACV,SACC,8EACD;AACJ,EAAC;AAEF,IAAa,cAAb,cAAiC,eAAmC;CAClE,OAAO,UAAU;AACf,SAAO;CACR;CAED,AAAS,OAAe;CAExB,AAAS,cACP;CAKF,AAAS,SAAS;CAElB;CAEA;CAEA;CAEA;CAEA;CAEA;CAEA;CAEA;CAEA;CAEA;CAEA;CAEA;CAEA;CAEA;CAEA;CAEA,AAAQ;CAER,YAAYC,SAAwC,CAAE,GAAE;EACtD,MAAM,OAAO;AAEb,MAAI,OAAO,OAAO,SAAS,UACzB,KAAK,OAAO,OAAO;AAGrB,MAAI,OAAO,OAAO,gBAAgB,UAChC,KAAK,cAAc,OAAO;AAG5B,MAAI,OAAO,YACT,KAAK,aAAa,OAAO;OACpB;GACL,MAAMC,mBACJ,CAAE;AACJ,OAAI,OAAO,cACT,iBAAiB,eAAe,OAAO;AAEzC,OAAI,OAAO,YACT,iBAAiB,aAAa,OAAO;GAEvC,KAAK,aAAa,IAAI,sBAAsB;EAC7C;EAED,KAAK,eAAe,OAAO;EAC3B,KAAK,gBAAgB,OAAO;EAC5B,KAAK,SAAS,OAAO;EACrB,KAAK,WAAW,OAAO;EACvB,KAAK,aAAa,OAAO;EACzB,KAAK,QAAQ,OAAO;EACpB,KAAK,eAAe,OAAO;EAC3B,KAAK,cAAc,OAAO;EAC1B,KAAK,gBAAgB,OAAO;EAC5B,KAAK,eAAe,OAAO;EAC3B,KAAK,iBAAiB,OAAO;EAC7B,KAAK,gBAAgB,OAAO;EAC5B,KAAK,aAAa,OAAO;EACzB,KAAK,iBAAiB,OAAO;CAC9B;CAED,MAAM,MACJC,OACAC,aACkD;AAClD,MAAI;GACF,MAAM,EACJ,KACA,cACA,aACA,eACA,cACA,gBACA,eACA,YACD,GAAG;GAGJ,MAAM,wBAAwB,KAAK;GACnC,MAAM,yBAAyB,KAAK;GACpC,MAAM,kBAAkB,KAAK;GAC7B,MAAM,oBAAoB,KAAK;GAC/B,MAAM,sBAAsB,KAAK;GACjC,MAAM,iBAAiB,KAAK;GAC5B,MAAM,wBAAwB,KAAK,gBAAgB;GACnD,MAAM,uBAAuB,KAAK,eAAe;GACjD,MAAM,yBAAyB,KAAK,iBAAiB;GACrD,MAAM,wBAAwB,KAAK,gBAAgB;GACnD,MAAM,0BAA0B,KAAK,kBAAkB;GACvD,MAAM,yBAAyB,KAAK,iBAAiB;GACrD,MAAM,0BAA0B,KAAK;GAErC,IAAIC;AACJ,OAAI,KAAK,YACP,sBAAsB,MAAM,KAAK,IAAI,IAAI,KAAK,YAAY;YACjD,YACT,sBAAsB,MAAM,KAAK,IAAI,IAAI,YAAY;QAErD,sBAAsB;GAGxB,MAAM,aAAa,MAAM,KAAK,WAAW,WAAW;IAClD;IACA,cAAc;IACd,eAAe;IACf,QAAQ;IACR,UAAU;IACV,YAAY;IACZ,OAAO;IACP,cAAc;IACd,aAAa;IACb,eAAe;IACf,cAAc;IACd,gBAAgB;IAChB,eAAe;IACf,YAAY;IACZ,gBAAgB;GACjB,EAAC;AAEF,OACE,CAAC,cACD,OAAO,eAAe,YACtB,EAAE,aAAa,eACf,CAAC,MAAM,QAAQ,WAAW,QAAQ,IAClC,WAAW,QAAQ,WAAW,GAC9B;IACA,MAAM,cAAc,oBAAoB,MAAM;IAE9C,MAAM,eACJ,CAAC,4BAA4B,EAAE,IAAI,gBAAG,EACtB,YAAY,KAAK,KAAK,CAAC,mEAAE,CAC0B;AAErE,UAAM,IAAI,MAAM;GACjB;AAED,UAAO;EACR,SAAQC,GAAY;GACnB,MAAM,eACJ,KAAK,OAAO,MAAM,YAAY,aAAa,IAAI,EAAE,UAAU,OAAO,EAAE;AAEtE,UAAO,EAAE,OAAO,aAAwB;EACzC;CACF;AACF"}